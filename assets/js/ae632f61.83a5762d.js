"use strict";(self.webpackChunkknowledge_base=self.webpackChunkknowledge_base||[]).push([[2671],{981:e=>{e.exports=JSON.parse('{"permalink":"/knowledge-base/blog/generative-ai-evaluation-methods","editUrl":"https://github.com/HinnyTsang/knowledge-base/tree/main/blog/blog/2025-05-16-generative-ai-evaluation.md","source":"@site/blog/2025-05-16-generative-ai-evaluation.md","title":"Generative AI Evaluation Methods","description":"The evaluation of generative AI models is a complex task that requires a combination of qualitative and quantitative methods. Here is the points that I summarized from the Machine Learning Operations with Vertex AI tutorial from Google.","date":"2025-05-16T00:00:00.000Z","tags":[{"inline":false,"label":"Generative AI","permalink":"/knowledge-base/blog/tags/generative-ai","description":"Generative AI"}],"readingTime":2.145,"hasTruncateMarker":true,"authors":[{"name":"Hinny Tsang","title":"Data Scientist @ Pollock Asset Management","url":"https://github.com/HinnyTsang","page":{"permalink":"/knowledge-base/blog/authors/hinnytsang"},"socials":{"linkedin":"https://www.linkedin.com/in/HinnyTsang/","github":"https://github.com/HinnyTsang"},"imageURL":"https://github.com/HinnyTsang.png","key":"hinnytsang"}],"frontMatter":{"slug":"generative-ai-evaluation-methods","title":"Generative AI Evaluation Methods","authors":["hinnytsang"],"tags":["generative-ai"]},"unlisted":false,"prevItem":{"title":"Quant Interview Questions 1","permalink":"/knowledge-base/blog/quant-interview-questions-1"},"nextItem":{"title":"Ito\'s Lamma","permalink":"/knowledge-base/blog/ito-lamma"}}')},3894:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>c});var t=i(981),a=i(4848),s=i(8453);const l={slug:"generative-ai-evaluation-methods",title:"Generative AI Evaluation Methods",authors:["hinnytsang"],tags:["generative-ai"]},o=void 0,r={authorsImageUrls:[void 0]},c=[];function d(e){const n={li:"li",ol:"ol",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:"The evaluation of generative AI models is a complex task that requires a combination of qualitative and quantitative methods. Here is the points that I summarized from the Machine Learning Operations with Vertex AI tutorial from Google."}),"\n",(0,a.jsx)(n.p,{children:"In general, the evaluation methods can be categorized into several types:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Binary Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"e.g. positive or negative sentiment analysis, spam detection, and appropriate content detection."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Category Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"e.g. topic classification, sentiment analysis including neutral, and product rating."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Ranking Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Rank the relative quality for different outputs."}),"\n",(0,a.jsx)(n.li,{children:"e.g. ranking search results, ranking product recommendations, and ranking news articles."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Numerical Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Assigns a quantitative score to model output."}),"\n",(0,a.jsx)(n.li,{children:"e.g. BLEU, ROUGE, METEOR, perplexity, and F1 score."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Text Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Evaluation of the text by human."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Multi-task Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Mixture of the above methods."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The choice of evaluation method depends on the specific task and the goals of the evaluation. Below are some examples:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Lexical Similarity"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Measure the similarity between the model's output and reference text, based on word overlap, sequence of words, or semantic similarity."}),"\n",(0,a.jsx)(n.li,{children:"e.g. BLEU focuses on n-gram overlap, ROUGE focuses on recall, and METEOR focuses on both precision and recall."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Linguistic Quality"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Evaluate the fluency, coherence, and grammatical correctness of the generated text."}),"\n",(0,a.jsx)(n.li,{children:"e.g. Perplexity, BLEURT."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Task-Specific Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Evaluate the performance of the model on specific tasks, such as summarization, translation, or question answering."}),"\n",(0,a.jsx)(n.li,{children:"e.g. BLEU for translation, and ROUGE for summarization."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Safety and fairness"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Evaluate the model's output for safety and fairness, including bias detection and harmful content detection."}),"\n",(0,a.jsx)(n.li,{children:"e.g. toxicity detection, hate speech detection, and bias detection or even human evaluation."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Groundedness"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Evaluate the factual accuracy of the model's output."}),"\n",(0,a.jsx)(n.li,{children:"e.g. Fact-checking tools, knowledge-based integration and human evaluation."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"User-Centric Evaluation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Focus on the user experience and satisfaction with the model's output."}),"\n",(0,a.jsx)(n.li,{children:"e.g. User survey."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Moreover, there are some common evaluation paradigms:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Pointwise Evaluation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Evaluating model behavior in production."}),"\n",(0,a.jsx)(n.li,{children:"Absolute performance of a single model."}),"\n",(0,a.jsx)(n.li,{children:"Identifying behaviors to prioritize for tuning."}),"\n",(0,a.jsx)(n.li,{children:"Establishing a baseline for model performance."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Pairwise Evaluation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Comparison of two models."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Evaluation methods are not only computation based, but also be model based, using LLM as a judge to evaluate the model output (Google Auto Side by Side). In summary, the choice of evaluation method depends on the specific task and the goals of the evaluation. I may talk about more about the evaluation metrics in the future."})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var t=i(6540);const a={},s=t.createContext(a);function l(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);